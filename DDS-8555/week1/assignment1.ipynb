{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e173296f",
   "metadata": {},
   "source": [
    "assignment1: this assignment builds \n",
    "1. 2 regression models for calculating sepal width then compares them and prints stats for comparing models\n",
    "2. 2 classification models for calculating type using quarantiles and prints stats for comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95fc15cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "  type  \n",
      "0    0  \n",
      "1    0  \n",
      "2    0  \n",
      "3    0  \n",
      "4    0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "    type  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "..   ...  \n",
       "145    2  \n",
       "146    2  \n",
       "147    2  \n",
       "148    2  \n",
       "149    2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn import datasets \n",
    "import pandas as pd\n",
    "\n",
    "iris= pd.DataFrame(datasets.load_iris().data) \n",
    "iris.columns = datasets.load_iris().feature_names \n",
    "\n",
    "iris['type'] = datasets.load_iris().target \n",
    "\n",
    "iris['type']=iris['type'].astype('object') \n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(iris.head())\n",
    "\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36f2bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['new']=(iris.iloc[:,0]*iris.iloc[:,1])/(iris.iloc[:,2]*iris.iloc[:,3])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35013865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "145    2\n",
       "146    2\n",
       "147    2\n",
       "148    2\n",
       "149    2\n",
       "Name: type, Length: 150, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.iloc[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a7988",
   "metadata": {},
   "source": [
    "Sample 80% of the data for a training set stratifying on ‘type’ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd1d78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts \n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(iris.iloc[:,0:4], iris.iloc[:,5], test_size=0.2, random_state=42,stratify=iris.iloc[:,4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d9d806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30, 120, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505fa49c",
   "metadata": {},
   "source": [
    "build regression models and print ME, MPE, MAE, MSE, MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22c545af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ME: -0.677 \n",
      " MPE: -0.237 \n",
      " MAE: 0.694 \n",
      " MSE: 0.602 \n",
      " MAPE: 0.242\n",
      "\n",
      " ME: -1.543 \n",
      " MPE: -0.522 \n",
      " MAE: 1.543 \n",
      " MSE: 2.526 \n",
      " MAPE: 0.522\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "from sklearn.metrics import mean_squared_error as MSE, mean_absolute_error as MAE\n",
    "\n",
    "def myf(y,yhat): \n",
    "    ME=np.round(np.mean(y-yhat),3) \n",
    "    MPE=np.round(np.mean((y-yhat)/y),3) \n",
    "    myMAE=np.round(MAE(y,yhat),3) \n",
    "    myMSE=np.round(MSE(y,yhat),3) \n",
    "    myMAPE=np.round(MAPE(y,yhat),3) \n",
    "    print(\"\\n\",\"ME:\", np.round(ME,3),\"\\n\",\"MPE:\",MPE,\"\\n\", \"MAE:\",  \n",
    "        myMAE,\"\\n\", \"MSE:\", myMSE,\"\\n\",\"MAPE:\",myMAPE) \n",
    "\n",
    "est1=np.mean(X_train['petal length (cm)']) \n",
    "\n",
    "est2=np.mean(X_train['sepal length (cm)']-X_train['petal width (cm)']) \n",
    "\n",
    "est1=[est1]*len(y_test) \n",
    "\n",
    "est2=[est2]*len(y_test) \n",
    "\n",
    "\n",
    "myf(X_test['sepal width (cm)'],est1) \n",
    "\n",
    "myf(X_test['sepal width (cm)'],est2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5612f14b",
   "metadata": {},
   "source": [
    "On the test set, evaluate the two classifiers (built on the training set) below for ‘type’ using accuracy, precision, recall, and the F1 score.  \n",
    "Up to 1st quantile of sepal length = type 0, >1st up to 2d quantile = type 1, >2d quantile = type 2 \n",
    "\n",
    "Up to 2d quantile of sepal length = type 0, >2d up to 3d quantile = type 1, >3d quantile = type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e73139a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.35      0.86      0.50         7\n",
      "           3       0.00      0.00      0.00         6\n",
      "          42       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          66       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.20        30\n",
      "   macro avg       0.03      0.06      0.04        30\n",
      "weighted avg       0.08      0.20      0.12        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from numpy import percentile \n",
    "from sklearn.metrics import confusion_matrix as cm, ConfusionMatrixDisplay as cmd \n",
    "from sklearn.metrics import classification_report as cr \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "est3=percentile(X_train['sepal length (cm)'], [25, 50]) \n",
    "est4=percentile(X_train['sepal length (cm)'], [50,75]) \n",
    "\n",
    "y_hat=np.zeros(len(y_test)) \n",
    "\n",
    "y_hat[X_test['sepal length (cm)']>est3[0]]=1 \n",
    "\n",
    "y_hat[X_test['sepal length (cm)']>est3[1]]=2 \n",
    "\n",
    "y_hat=y_hat.astype('int') \n",
    "\n",
    "print(cr(y_test.astype('int'),y_hat)) \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7abba20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.12      0.14      0.13         7\n",
      "           2       0.11      0.14      0.12         7\n",
      "           3       0.00      0.00      0.00         6\n",
      "          42       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          66       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.07        30\n",
      "   macro avg       0.02      0.02      0.02        30\n",
      "weighted avg       0.06      0.07      0.06        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\anujb\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_hat2=np.zeros(len(y_test)) \n",
    "\n",
    "y_hat2[X_test['sepal length (cm)']>est4[0]]=1 \n",
    "\n",
    "y_hat2[X_test['sepal length (cm)']>est4[1]]=2 \n",
    "\n",
    "y_hat2=y_hat2.astype('int') \n",
    "\n",
    "print(cr(y_test.astype('int'),y_hat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71425019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
